<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LlamaIndex on Techiedeepdive</title>
    <link>/tags/llamaindex/</link>
    <description>Recent content in LlamaIndex on Techiedeepdive</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Sat, 22 Mar 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/llamaindex/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LiteLLM - One LLM proxy to rule them all</title>
      <link>/posts/2025/03/litellm-one-llm-proxy-to-rule-them-all/</link>
      <pubDate>Sat, 22 Mar 2025 00:00:00 +0000</pubDate>
      <guid>/posts/2025/03/litellm-one-llm-proxy-to-rule-them-all/</guid>
      <description>&lt;p&gt;The tagline for LiteLLM is simple and awesome&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Call 100+ LLMs using the same Input/Output Format&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;hello-world&#34;&gt;&#xA;  Hello world&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#hello-world&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This is a small example from LiteLLM docs using Ollama. I have Ollama running locally, so that was easy.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ff7b72&#34;&gt;from&lt;/span&gt; &lt;span style=&#34;color:#ff7b72&#34;&gt;litellm&lt;/span&gt; &lt;span style=&#34;color:#ff7b72&#34;&gt;import&lt;/span&gt; completion&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;response &lt;span style=&#34;color:#ff7b72;font-weight:bold&#34;&gt;=&lt;/span&gt; completion(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#ff7b72;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;ollama/llama2&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    messages&lt;span style=&#34;color:#ff7b72;font-weight:bold&#34;&gt;=&lt;/span&gt;[{ &lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;content&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;respond in 20 words. who are you?&amp;#34;&lt;/span&gt;, &lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;role&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;user&amp;#34;&lt;/span&gt; }],&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    api_base&lt;span style=&#34;color:#ff7b72;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#a5d6ff&#34;&gt;&amp;#34;http://localhost:11434&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(response)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;&#xA;&lt;p&gt;ModelResponse(id=&amp;lsquo;chatcmpl-d1c86df4-5feb-419d-8e8a-fd876ad46085&amp;rsquo;, choices=[Choices(finish_reason=&amp;lsquo;stop&amp;rsquo;, index=0, message=Message(content=&amp;ldquo;I&amp;rsquo;m just an AI assistant, here to help!&amp;rdquo;, role=&amp;lsquo;assistant&amp;rsquo;))], created=1716627590, model=&amp;lsquo;ollama/llama2&amp;rsquo;, object=&amp;lsquo;chat.completion&amp;rsquo;, system_fingerprint=None, usage=Usage(prompt_tokens=31, completion_tokens=14, total_tokens=45))&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
