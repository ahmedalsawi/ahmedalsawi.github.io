<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  Ollama - Hello world · Techiedeepdive
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="description" content="This is a quick hello world to run local model with Ollama.

  Ollama docker
  
    
    Link to heading
  

The simplest way is running Ollama docker. To create the container, we just to fire up 2 commands.
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
docker exec -it ollama ollama run llama2
You also can open a shell that container with
docker exec -it ollama bash
Side note, Sometimes the containers can linger around, so we need to clean up the containers before restarting a new one.">
<meta name="keywords" content="homepage, blog">



  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="/">
  <meta name="twitter:title" content="Ollama - Hello world">
  <meta name="twitter:description" content="This is a quick hello world to run local model with Ollama.
Ollama docker Link to heading The simplest way is running Ollama docker. To create the container, we just to fire up 2 commands.
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama docker exec -it ollama ollama run llama2 You also can open a shell that container with
docker exec -it ollama bash Side note, Sometimes the containers can linger around, so we need to clean up the containers before restarting a new one.">

<meta property="og:url" content="/posts/2024/12/ollama-hello-world/">
  <meta property="og:site_name" content="Techiedeepdive">
  <meta property="og:title" content="Ollama - Hello world">
  <meta property="og:description" content="This is a quick hello world to run local model with Ollama.
Ollama docker Link to heading The simplest way is running Ollama docker. To create the container, we just to fire up 2 commands.
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama docker exec -it ollama ollama run llama2 You also can open a shell that container with
docker exec -it ollama bash Side note, Sometimes the containers can linger around, so we need to clean up the containers before restarting a new one.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-02T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-12-02T00:00:00+00:00">
    <meta property="article:tag" content="Llm">
    <meta property="article:tag" content="Ollama">
    <meta property="og:image" content="/">




<link rel="canonical" href="/posts/2024/12/ollama-hello-world/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.aa5ef26fa979d6793724ae2dbd71efa94fd16cb1c5c7db3b6651f21f9892a5fd.css" integrity="sha256-ql7yb6l51nk3JK4tvXHvqU/RbLHFx9s7ZlHyH5iSpf0=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="/">
      Techiedeepdive
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/posts">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/reading-list/">Reading list</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/tags/">Tags</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="/posts/2024/12/ollama-hello-world/">
              Ollama - Hello world
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2024-12-02T00:00:00Z">
                December 2, 2024
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              2-minute read
            </span>
          </div>
          
          
          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/llm/">Llm</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/ollama/">Ollama</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <p>This is a quick hello world to run local model with Ollama.</p>
<h1 id="ollama-docker">
  Ollama docker
  <a class="heading-link" href="#ollama-docker">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>The simplest way is running Ollama docker. To create the container, we just to fire up 2 commands.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
</span></span><span style="display:flex;"><span>docker exec -it ollama ollama run llama2
</span></span></code></pre></div><p>You also can open a shell that container with</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker exec -it ollama bash
</span></span></code></pre></div><p>Side note, Sometimes the containers can linger around, so we need to clean up the containers before restarting a new one.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>docker ps
</span></span><span style="display:flex;"><span>docker container prune
</span></span></code></pre></div><h1 id="ollama-build">
  Ollama build
  <a class="heading-link" href="#ollama-build">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>Another option is building ollama from source. This needs recent version of go (&gt;2.1 i think).</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>make -j <span style="color:#a5d6ff">4</span>
</span></span><span style="display:flex;"><span>go build .
</span></span></code></pre></div><p>In one terminal, Let&rsquo;s start the server.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama serve
</span></span></code></pre></div><p>In another terminal, let&rsquo;s run ollama shell with llama3.2. This will take a while the first time as it needs to download the model.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>ollama run llama3.2
</span></span></code></pre></div><h1 id="ollama-with-python-ollama">
  Ollama with python ollama
  <a class="heading-link" href="#ollama-with-python-ollama">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>An easy way to access Ollama end points, is to use the <code>ollama</code> python package.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff7b72">import</span> <span style="color:#ff7b72">ollama</span>
</span></span><span style="display:flex;"><span>response <span style="color:#ff7b72;font-weight:bold">=</span> ollama<span style="color:#ff7b72;font-weight:bold">.</span>chat(model<span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#39;llama2&#39;</span>, messages<span style="color:#ff7b72;font-weight:bold">=</span>[
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#39;role&#39;</span>: <span style="color:#a5d6ff">&#39;user&#39;</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#a5d6ff">&#39;content&#39;</span>: <span style="color:#a5d6ff">&#39;Why is the sky blue?&#39;</span>,
</span></span><span style="display:flex;"><span>  },
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>print(response[<span style="color:#a5d6ff">&#39;message&#39;</span>][<span style="color:#a5d6ff">&#39;content&#39;</span>])
</span></span></code></pre></div><h1 id="ollama-with-llamaindex">
  Ollama with lLamaIndex
  <a class="heading-link" href="#ollama-with-llamaindex">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h1>
<p>or if you are llamaIndex fan, we can use the ollama integration with those 2 packages.</p>
<div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>!pip install llama-index
</span></span><span style="display:flex;"><span>!pip install llama-index-embeddings-ollama llama-index-llms-ollama
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#e6edf3;background-color:#0d1117;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff7b72">from</span> <span style="color:#ff7b72">llama_index.llms.ollama</span> <span style="color:#ff7b72">import</span> Ollama
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>llm <span style="color:#ff7b72;font-weight:bold">=</span> Ollama(model<span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">&#34;llama2&#34;</span>, request_timeout<span style="color:#ff7b72;font-weight:bold">=</span><span style="color:#a5d6ff">30000.0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>resp <span style="color:#ff7b72;font-weight:bold">=</span> llm<span style="color:#ff7b72;font-weight:bold">.</span>complete(<span style="color:#a5d6ff">&#34;Who is Paul Graham?&#34;</span>)
</span></span><span style="display:flex;"><span>print(resp)
</span></span></code></pre></div><p>That&rsquo;s it.</p>

      </div>


      <footer>
        


        
        
        
        
        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2024
    
    ·
    
      Licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA-4.0</a>
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
